# -*- coding: utf-8 -*-
"""design_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/178yJARWfxMmwrk5sgIuvFIG-oEl0l-yF
"""

# !pip install --upgrade torch torchvision torchaudio
# !pip install controlnet_aux
# !pip install --upgrade xformers # Install xformers
import os
import torch
import numpy as np
import cv2
from PIL import Image, ImageDraw
import requests
from transformers import YolosForObjectDetection, YolosImageProcessor
from diffusers import StableDiffusionControlNetPipeline, ControlNetModel, UniPCMultistepScheduler
from controlnet_aux import OpenposeDetector, MLSDdetector, HEDdetector
import matplotlib.pyplot as plt
from huggingface_hub import login
import re
import random

class RoomTransformer:
    def __init__(self, auth_token=None):
        """Initialize the RoomTransformer with required models.

        Args:
            auth_token (str, optional): HuggingFace auth token for accessing gated models
        """
        # Set up device
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"Using device: {self.device}")

        # Login to Hugging Face if token provided
        if auth_token:
            login(auth_token)

        # Load object detection model
        print("Loading object detection model...")
        self.obj_detector_processor = YolosImageProcessor.from_pretrained('hustvl/yolos-small')
        self.obj_detector = YolosForObjectDetection.from_pretrained('hustvl/yolos-small')
        self.obj_detector.to(self.device)

        # Load control models for structure detection
        print("Loading structure detection models...")
        self.mlsd_detector = MLSDdetector.from_pretrained("lllyasviel/ControlNet")

        # Load ControlNet models
        print("Loading ControlNet models...")
        controlnet_mlsd = ControlNetModel.from_pretrained(
            "lllyasviel/sd-controlnet-mlsd", torch_dtype=torch.float16
        )

        # Set up the main StableDiffusion pipeline with ControlNet
        print("Setting up StableDiffusion pipeline...")
        self.sd_pipeline = StableDiffusionControlNetPipeline.from_pretrained(
            "runwayml/stable-diffusion-v1-5",
            controlnet=controlnet_mlsd,
            torch_dtype=torch.float16
        )
        self.sd_pipeline.scheduler = UniPCMultistepScheduler.from_config(self.sd_pipeline.scheduler.config)
        self.sd_pipeline.to(self.device)
        #If you don't have a GPU or it's not enabled with CUDA, comment out the next line
        if torch.cuda.is_available():
            self.sd_pipeline.enable_xformers_memory_efficient_attention()
        #self.sd_pipeline.enable_xformers_memory_efficient_attention()

        # Dictionary of theme descriptions
        self.theme_descriptions = {
            "modern": "a clean, modern interior design with minimalist furniture, neutral colors, and sleek lines",
            "vintage": "a nostalgic vintage interior with antique furniture, warm colors, and classic patterns",
            "rustic": "a cozy rustic interior with wooden furniture, earthy tones, and natural materials",
            "industrial": "an industrial style interior with metal fixtures, exposed brick, and functional furniture",
            "scandinavian": "a bright Scandinavian interior with light wood, white walls, and functional minimalist furniture",
            "bohemian": "an eclectic bohemian interior with colorful textiles, plants, and mixed patterns",
            "mid-century": "a mid-century modern interior with iconic furniture pieces, clean lines, and geometric patterns",
            "coastal": "a breezy coastal interior with light blues, whites, and nautical accents",
            "traditional": "an elegant traditional interior with classic furniture, rich colors, and formal arrangements",
            "art deco": "a glamorous art deco interior with bold geometric patterns, luxurious materials, and ornate details"
        }

        # Dictionary of furniture arrangement patterns
        self.layout_patterns = {
            "living_room": {
                "conversation": "furniture arranged in a conversational layout with seating facing each other",
                "entertainment": "furniture arranged to focus on the TV/entertainment area",
                "open_concept": "furniture arranged to create an open, flowing space with clear pathways",
                "cozy": "furniture arranged in a cozy, intimate setting with close seating"
            },
            "bedroom": {
                #"symmetrical": "furniture arranged symmetrically around the bed for balance",
                "space_saving": "furniture arranged efficiently to maximize space",
                "luxurious": "furniture arranged to create a spacious, luxurious feel"
            },
            "office": {
                "productive": "furniture arranged for maximum productivity with ergonomic considerations",
                "collaborative": "furniture arranged to facilitate collaboration and meetings",
                "minimal": "furniture arranged in a minimal way to reduce distractions"
            },
            "dining": {
                "formal": "furniture arranged formally with the dining table as the centerpiece",
                "casual": "furniture arranged in a casual, relaxed dining arrangement",
                "breakfast_nook": "furniture arranged in a cozy breakfast nook style"
            }
        }

        # Last used furniture layout (for iterative refinement)
        self.last_room_type = None
        self.last_layout_type = None
        self.last_detected_objects = None
        self.last_structure_lines = None
        self.last_theme = None
        self.last_user_feedback = None

        print("Room Transformer initialized successfully!")

    def detect_objects(self, image):
        """Detect objects in the room image.

        Args:
            image (PIL.Image): Input image of the messy room

        Returns:
            dict: Detected objects with bounding boxes and labels
        """
        inputs = self.obj_detector_processor(images=image, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        with torch.no_grad():
            outputs = self.obj_detector(**inputs)

        # Process results
        target_sizes = torch.tensor([image.size[::-1]])
        results = self.obj_detector_processor.post_process_object_detection(
            outputs, threshold=0.3, target_sizes=target_sizes)[0]

        detected_objects = []
        for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
            detected_objects.append({
                "label": self.obj_detector.config.id2label[label.item()],
                "confidence": score.item(),
                "box": box.detach().cpu().numpy()
            })

        return detected_objects

    def analyze_room_structure(self, image):
        """Analyze the room structure to identify walls, floor, ceiling.

        Args:
            image (PIL.Image): Input image of the room

        Returns:
            np.ndarray: Line detection result for the room structure
        """
        # Convert PIL to numpy array
        img_np = np.array(image)

        # Detect structural lines using MLSD
        structure_lines = self.mlsd_detector(img_np)

        return structure_lines

    def identify_room_type(self, detected_objects):
        """Identify the type of room based on detected objects.

        Args:
            detected_objects (list): List of detected objects in the room

        Returns:
            str: Identified room type
        """
        # Extract object labels
        labels = [obj["label"] for obj in detected_objects]

        # Count occurrences of key furniture
        bed_count = labels.count("bed")
        sofa_count = labels.count("couch") + labels.count("sofa")
        desk_count = labels.count("desk")
        dining_table_count = labels.count("dining table")

        # Determine room type based on key furniture
        if bed_count > 0:
            return "bedroom"
        elif desk_count > 0 and sofa_count == 0:
            return "office"
        elif dining_table_count > 0 and sofa_count == 0:
            return "dining"
        else:
            return "living_room"  # Default to living room

    def suggest_layout(self, room_type):
        """Suggest an efficient furniture layout based on room type.

        Args:
            room_type (str): Type of room (living_room, bedroom, office, dining)

        Returns:
            tuple: (layout_type, layout_description)
        """
        # Get available layouts for the room type
        available_layouts = self.layout_patterns.get(room_type, self.layout_patterns["living_room"])

        # Select a layout type
        layout_type = random.choice(list(available_layouts.keys()))

        return layout_type, available_layouts[layout_type]

    def generate_theme_prompt(self, theme, detected_objects, room_type, layout_description, user_feedback=None):
        """Generate a detailed prompt based on the theme, detected objects, and layout.

        Args:
            theme (str): The design theme (e.g., "modern", "vintage")
            detected_objects (list): List of detected objects in the room
            room_type (str): Type of room (living_room, bedroom, etc.)
            layout_description (str): Description of the furniture layout
            user_feedback (str, optional): User feedback for refinement

        Returns:
            str: Detailed prompt for image generation
        """
        # Get theme description or use a generic one if theme not found
        theme_desc = self.theme_descriptions.get(
            theme.lower(),
            f"a beautiful {theme} style interior design"
        )

        # Extract furniture types from detected objects
        furniture_labels = ["chair", "sofa", "couch", "table", "bed", "bookshelf", "desk",
                          "dining table", "cabinet", "tv", "lamp", "rug", "carpet"]

        furniture = [obj["label"] for obj in detected_objects
                    if obj["label"] in furniture_labels]
        furniture_str = ", ".join(set(furniture)) if furniture else "furniture"

        # Room type specific descriptions
        room_descriptions = {
            "living_room": "living room",
            "bedroom": "bedroom",
            "office": "home office",
            "dining": "dining room"
        }
        room_str = room_descriptions.get(room_type, "room")

        # Create a detailed prompt
        prompt = f"A professionally designed {theme} style {room_str} with {furniture_str} arranged in {layout_description}. "
        prompt += f"{theme_desc}. "

        # Add specific furniture arrangement directions
        if room_type == "living_room":
            prompt += "The furniture is arranged to create good flow and conversation areas. "
        elif room_type == "bedroom":
            prompt += "The bed is positioned as the focal point with nightstands and other furniture arranged efficiently. "
        elif room_type == "office":
            prompt += "The desk is positioned for productivity with good ergonomics. "
        elif room_type == "dining":
            prompt += "The dining table is positioned centrally with chairs arranged neatly. "

        # Incorporate user feedback if provided
        if user_feedback:
            prompt += f"{user_feedback}. "

        # Add quality descriptors
        prompt += "High-end interior design, professional photography, 8k, highly detailed, efficient furniture arrangement."

        return prompt

    def transform_room(self, input_image_path, theme, output_path="transformed_room.png", user_feedback=None):
        """Transform a messy room into a well-designed room with the specified theme and efficient layout.

        Args:
            input_image_path (str): Path to the input image of the messy room
            theme (str): Design theme to apply
            output_path (str, optional): Path to save the output image
            user_feedback (str, optional): User feedback for refinement

        Returns:
            PIL.Image: Transformed room image
        """
        print(f"Starting room transformation with {theme} theme...")

        # Load input image
        if input_image_path.startswith("http"):
            response = requests.get(input_image_path, stream=True)
            input_image = Image.open(response.raw).convert("RGB")
        else:
            input_image = Image.open(input_image_path).convert("RGB")

        # Store user feedback for potential future iterations
        self.last_user_feedback = user_feedback

        # If we're refining an existing design and have cached data
        if user_feedback and self.last_detected_objects and self.last_structure_lines and self.last_room_type and self.last_layout_type:
            detected_objects = self.last_detected_objects
            structure_lines = self.last_structure_lines
            room_type = self.last_room_type
            layout_type = self.last_layout_type
            layout_description = self.layout_patterns[room_type][layout_type]
            print(f"Refining existing {room_type} design with {layout_type} layout based on feedback...")

        else:
            # Step 1: Detect objects in the room
            print("Detecting objects in the room...")
            detected_objects = self.detect_objects(input_image)
            print(f"Detected {len(detected_objects)} objects in the room")
            self.last_detected_objects = detected_objects

            # Step 2: Analyze room structure
            print("Analyzing room structure...")
            structure_lines = self.analyze_room_structure(input_image)
            self.last_structure_lines = structure_lines

            # Step 3: Identify room type and suggest layout
            room_type = self.identify_room_type(detected_objects)
            self.last_room_type = room_type
            layout_type, layout_description = self.suggest_layout(room_type)
            self.last_layout_type = layout_type

            print(f"Identified room type: {room_type}")
            print(f"Suggested layout: {layout_type} - {layout_description}")

        # Step 4: Generate prompt based on theme, detected objects, room type, and layout
        prompt = self.generate_theme_prompt(
            theme,
            detected_objects,
            room_type,
            self.layout_patterns[room_type][layout_type],
            user_feedback
        )

        print(f"Generated prompt: {prompt}")

        # Store the theme for potential future iterations
        self.last_theme = theme

        # Step 5: Generate the transformed room image
        print("Generating transformed room image...")
        negative_prompt = "messy, cluttered, disorganized, bad quality, low resolution, blurry"

        # Run the pipeline
        output_image = self.sd_pipeline(
            prompt,
            structure_lines,
            negative_prompt=negative_prompt,
            num_inference_steps=30,
            guidance_scale=7.5,
        ).images[0]

        # Save the output image
        output_image.save(output_path)
        print(f"Transformed room image saved to {output_path}")

        return output_image

    def get_user_feedback(self):
        """Get user feedback for iterative refinement.

        Returns:
            str: User feedback
        """
        print("\n=== DESIGN FEEDBACK ===")
        print("How would you like to refine the design? Examples:")
        print("- 'Add more plants'")
        print("- 'Make it brighter'")
        print("- 'Use warmer colors'")
        print("- 'Rearrange furniture to be more open'")
        print("- 'Add a reading corner'")
        print("- 'Include artwork on the walls'")

        feedback = input("Enter your feedback (or 'done' to finish): ")

        return None if feedback.lower() == 'done' else feedback

    def visualize_results(self, input_image_path, output_image_path, detected_objects=None):
        """Visualize the transformation results.

        Args:
            input_image_path (str): Path to the input image
            output_image_path (str): Path to the output image
            detected_objects (list, optional): List of detected objects for visualization
        """
        # Load images
        if input_image_path.startswith("http"):
            response = requests.get(input_image_path, stream=True)
            input_image = Image.open(response.raw).convert("RGB")
        else:
            input_image = Image.open(input_image_path).convert("RGB")

        output_image = Image.open(output_image_path).convert("RGB")

        # Create figure
        fig, axes = plt.subplots(1, 2, figsize=(20, 10))

        # Plot input image with detected objects if available
        axes[0].imshow(input_image)
        axes[0].set_title("Original Room")

        if detected_objects:
            # Draw bounding boxes on a copy of the input image
            input_with_boxes = input_image.copy()
            draw = ImageDraw.Draw(input_with_boxes)

            for obj in detected_objects:
                box = obj["box"].astype(int)
                label = obj["label"]
                draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline="red", width=3)
                draw.text((box[0], box[1] - 10), label, fill="red")

            axes[0].imshow(input_with_boxes)

        # Plot output image
        axes[1].imshow(output_image)
        axes[1].set_title(f"Transformed Room")

        for ax in axes:
            ax.axis("off")

        plt.tight_layout()
        plt.savefig("comparison_new.png")
        plt.show()


# Example usage
def main(input_image_path, theme, hf_token=None):
    """Main function to run the room transformation with iterative feedback.

    Args:
        input_image_path (str): Path to the input messy room image
        theme (str): Design theme to apply
        hf_token (str, optional): HuggingFace auth token for accessing gated models
    """
    # Initialize the room transformer
    transformer = RoomTransformer(auth_token=hf_token)

    # Initial transformation
    output_path = "transformed_room_new.png"
    transformed_image = transformer.transform_room(
        input_image_path=input_image_path,
        theme=theme,
        output_path=output_path
    )

    # Visualize initial results
    transformer.visualize_results(
        input_image_path=input_image_path,
        output_image_path=output_path,
        detected_objects=transformer.last_detected_objects
    )

    # Iterative refinement loop
    iteration = 1
    while True:
        # Get user feedback
        feedback = transformer.get_user_feedback()

        # Exit loop if no feedback or user is done
        if not feedback:
            print("Design finalized!")
            break

        # Update output path for this iteration
        iteration_output_path = f"transformed_room_iteration_{iteration}.png"

        # Apply refinements based on feedback
        print(f"\nApplying refinements (iteration {iteration})...")
        transformed_image = transformer.transform_room(
            input_image_path=input_image_path,
            theme=theme,
            output_path=iteration_output_path,
            user_feedback=feedback
        )

        # Visualize refined results
        transformer.visualize_results(
            input_image_path=output_path,  # Use previous output as "before" image
            output_image_path=iteration_output_path,
            detected_objects=None  # No need to show detection boxes on refinement
        )

        # Update the reference output path for the next iteration
        output_path = iteration_output_path
        iteration += 1

    return transformed_image


if __name__ == "__main__":
    # Replace with your image path and desired theme
    input_image = "/content/real_room.jpg"  # Can be a local path or URL
    theme = input("Enter the theme you want (modern, vintage, rustic, etc.): ")

    # Optional: HuggingFace auth token for accessing gated models
    hf_token = "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"  # Your HuggingFace auth token here

    main(input_image, theme, hf_token)